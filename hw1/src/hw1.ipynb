{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(csv_path, audio_folder_path):\n",
    "    track_df = pd.read_csv(csv_path)\n",
    "\n",
    "    audio_dict = {\n",
    "        \"track\": [],\n",
    "        \"y\": [],\n",
    "        \"sr\": [],\n",
    "    }\n",
    "\n",
    "    for track_name in track_df[\"track\"]:\n",
    "        print(f\"loading {track_name}\")\n",
    "        y, sr = librosa.load(f\"{audio_folder_path}/{track_name}\")\n",
    "        audio_dict[\"track\"].append(track_name)\n",
    "        audio_dict[\"y\"].append(y)\n",
    "        audio_dict[\"sr\"].append(sr)\n",
    "\n",
    "    return track_df, pd.DataFrame(audio_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading normalize_5s_intro_thc1MtNagC8.wav\n",
      "loading normalize_5s_intro_Wo2qUD1g7xM.wav\n",
      "loading normalize_5s_intro_3ObVN3QQiZ8.wav\n",
      "loading normalize_5s_intro_S-zQJFRX5Fg.wav\n",
      "loading normalize_5s_intro_SyZOAgXiPMw.wav\n",
      "loading normalize_5s_intro_GQT8ejgV2_A.wav\n",
      "loading normalize_5s_intro_PQAIxeSIQU4.wav\n",
      "loading normalize_5s_intro_E-8pyVBvCPQ.wav\n",
      "loading normalize_5s_intro_Qr8eZSVaw10.wav\n",
      "loading normalize_5s_intro_p7j-tz1Cn4o.wav\n",
      "loading normalize_5s_intro_nISI4qF55F4.wav\n",
      "loading normalize_5s_intro_RoeRU5zxkak.wav\n",
      "loading normalize_5s_intro_EygNk739nnY.wav\n",
      "loading normalize_5s_intro_w1G3rqVil1s.wav\n",
      "loading normalize_5s_intro_KKc_RMln5UY.wav\n",
      "loading normalize_5s_intro_Ng2JdroNfC0.wav\n",
      "loading normalize_5s_intro_xc0sWhVhmkw.wav\n",
      "loading normalize_5s_intro_VVRszjvg3_U.wav\n",
      "loading normalize_5s_intro_C7u6rtswjCU.wav\n",
      "loading normalize_5s_intro_HiPkwl5p1GY.wav\n",
      "loading normalize_5s_intro_mYa_9d2Daas.wav\n",
      "loading normalize_5s_intro_6MSYrN4YfKY.wav\n",
      "loading normalize_5s_intro_O2q_9lBDM7I.wav\n",
      "loading normalize_5s_intro_7E_a_VKjcl8.wav\n",
      "loading normalize_5s_intro_a8cJLohQ_Jg.wav\n",
      "loading normalize_5s_intro_7zz-nEVKZdc.wav\n",
      "loading normalize_5s_intro_JeGhUESd_1o.wav\n",
      "loading normalize_5s_intro_IN1f9k8qVDk.wav\n",
      "loading normalize_5s_intro_RhBb77hG0iw.wav\n",
      "loading normalize_5s_intro_qAiwzv8N7rM.wav\n",
      "loading normalize_5s_intro_AoB8koE95C0.wav\n",
      "loading normalize_5s_intro_j3DigipQ_hQ.wav\n",
      "loading normalize_5s_intro_1X0SdKtnwo8.wav\n",
      "loading normalize_5s_intro_RCJx5VW-fQI.wav\n",
      "loading normalize_5s_intro_S_-qkv0NZ1g.wav\n",
      "loading normalize_5s_intro_C90sY_Ht6Ig.wav\n",
      "loading normalize_5s_intro_Z5gvqq3ChII.wav\n",
      "loading normalize_5s_intro_zumMQrI_tMg.wav\n",
      "loading normalize_5s_intro_gwsaElRJI2M.wav\n",
      "loading normalize_5s_intro_ftjEcrrf7r0.wav\n",
      "loading normalize_5s_intro_ZBBS4imv1qo.wav\n",
      "loading normalize_5s_intro_DyQ_9p6y89c.wav\n",
      "loading normalize_5s_intro_vgZv7Uu4YrA.wav\n",
      "loading normalize_5s_intro_wcLXjQLwSBE.wav\n",
      "loading normalize_5s_intro_7LuQQP-DAoc.wav\n",
      "loading normalize_5s_intro_BEo0rqOZIng.wav\n",
      "loading normalize_5s_intro_n4HTXYR-2AI.wav\n",
      "loading normalize_5s_intro_72T4j04MS8o.wav\n",
      "loading normalize_5s_intro_6TT_UgrRHq8.wav\n",
      "loading normalize_5s_intro_uo8qDCDZhK0.wav\n",
      "loading normalize_5s_intro_Et-YdmSo_3A.wav\n",
      "loading normalize_5s_intro_oxKbrl4kyg8.wav\n",
      "loading normalize_5s_intro_XgwqnGG-pbI.wav\n",
      "loading normalize_5s_intro_1wpJkzCWHcI.wav\n",
      "loading normalize_5s_intro_bwQ49N0jVvE.wav\n",
      "loading normalize_5s_intro_OMR2W-7AyYU.wav\n",
      "loading normalize_5s_intro_sjlkxcwhpwA.wav\n",
      "loading normalize_5s_intro_4F1wvsJXXVY.wav\n",
      "loading normalize_5s_intro_YEq-cvq_cK4.wav\n",
      "loading normalize_5s_intro_42O51bcJyq0.wav\n",
      "loading normalize_5s_intro_5FYAICvv-d0.wav\n",
      "loading normalize_5s_intro_yBzk2xXE9yg.wav\n",
      "loading normalize_5s_intro_zEWSSod0zTY.wav\n",
      "loading normalize_5s_intro_dvf--10EYXw.wav\n",
      "loading normalize_5s_intro_xQOXxmznGPg.wav\n",
      "loading normalize_5s_intro_hMWoOunsMFM.wav\n",
      "loading normalize_5s_intro_TnsOVDCq_b0.wav\n",
      "loading normalize_5s_intro_Yh78Ll6-ODQ.wav\n",
      "loading normalize_5s_intro_IYnu4-69fTA.wav\n",
      "loading normalize_5s_intro_SubIr_Fyp4M.wav\n",
      "loading normalize_5s_intro_WrRAZVJGImw.wav\n",
      "loading normalize_5s_intro_gFnNr5vr5bQ.wav\n",
      "loading normalize_5s_intro_j9KKh215HTs.wav\n",
      "loading normalize_5s_intro_XBTT9tSVsh0.wav\n",
      "loading normalize_5s_intro_u8BxVzRG9bE.wav\n",
      "loading normalize_5s_intro_SQBuVfTX1ME.wav\n",
      "loading normalize_5s_intro_-MqZKMbOYEA.wav\n",
      "loading normalize_5s_intro_IpniN1Wq68Y.wav\n",
      "loading normalize_5s_intro_1lunUbvf35M.wav\n",
      "loading normalize_5s_intro_zk04E79riMQ.wav\n",
      "loading normalize_5s_intro_uUfPwlxFFJM.wav\n",
      "loading normalize_5s_intro_Ws-QlpSltr8.wav\n",
      "loading normalize_5s_intro_xT1eOeXlTXg.wav\n",
      "loading normalize_5s_intro_1Ngn3fZIK2E.wav\n",
      "loading normalize_5s_intro_2JL_KcEzkqg.wav\n",
      "loading normalize_5s_intro_4jvQFLlRQlo.wav\n",
      "loading normalize_5s_intro_AjGkbFqi67c.wav\n",
      "loading normalize_5s_intro_ahpmuikko3U.wav\n",
      "loading normalize_5s_intro_sY5wXfgspQI.wav\n",
      "loading normalize_5s_intro_HMvXE4Zs6ZA.wav\n",
      "loading normalize_5s_intro_gv7BRXvZJbI.wav\n",
      "loading normalize_5s_intro_4wgo8K28RNM.wav\n",
      "loading normalize_5s_intro_2ySLmwsfP4Q.wav\n",
      "loading normalize_5s_intro_MY4YJxn-9Og.wav\n",
      "loading normalize_5s_intro_3gjfHYZ873o.wav\n",
      "loading normalize_5s_intro_csHiDQXIggE.wav\n",
      "loading normalize_5s_intro_C5VCGM2J5ls.wav\n",
      "loading normalize_5s_intro_ey4Fc9DP5Rw.wav\n",
      "loading normalize_5s_intro_bI7xde9-3BI.wav\n",
      "loading normalize_5s_intro_EfZ-dVDySzc.wav\n",
      "loading normalize_5s_intro_Zh3uBgwow8A.wav\n",
      "loading normalize_5s_intro_JQTlG7NxJek.wav\n",
      "loading normalize_5s_intro_1CrxzClzLvs.wav\n",
      "loading normalize_5s_intro_0aC-jOKuBFE.wav\n",
      "loading normalize_5s_intro_xePw8n4xu8o.wav\n",
      "loading normalize_5s_intro_lEHM9HZf0IA.wav\n",
      "loading normalize_5s_intro_xhmtXrtLkgo.wav\n",
      "loading normalize_5s_intro_hHItMz0gfaU.wav\n",
      "loading normalize_5s_intro_99f0oH45TVc.wav\n",
      "loading normalize_5s_intro_co6WMzDOh1o.wav\n",
      "loading normalize_5s_intro_xqzOxMdhmzU.wav\n",
      "loading normalize_5s_intro_h-nnAeByB1A.wav\n",
      "loading normalize_5s_intro_TFv9Kcym9dg.wav\n",
      "loading normalize_5s_intro_tEW2eRQ-4DY.wav\n",
      "loading normalize_5s_intro_VAc0xuVa7jI.wav\n",
      "loading normalize_5s_intro_PALMMqZLAQk.wav\n",
      "loading normalize_5s_intro_STpRa2JPFA0.wav\n",
      "loading normalize_5s_intro_SgJMnEdtTXA.wav\n",
      "loading normalize_5s_intro_NL2ZHPji3Z0.wav\n",
      "loading normalize_5s_intro_EVSuxb6Ywcg.wav\n",
      "loading normalize_5s_intro_wAJMhJpSCIc.wav\n",
      "loading normalize_5s_intro_GphIn74Weu0.wav\n",
      "loading normalize_5s_intro_gue_crpFdSE.wav\n",
      "loading normalize_5s_intro_oQ0O2cd1T04.wav\n",
      "loading normalize_5s_intro_vMcFA2x23FE.wav\n",
      "loading normalize_5s_intro_FhvXg70ycrM.wav\n",
      "loading normalize_5s_intro_lE_747E_Sdg.wav\n",
      "loading normalize_5s_intro_i0MrGb1hT2U.wav\n",
      "loading normalize_5s_intro_bI8-2blisUM.wav\n",
      "loading normalize_5s_intro_aQ06TfyA1Ks.wav\n",
      "loading normalize_5s_intro_ZvrysfBDzSs.wav\n",
      "loading normalize_5s_intro_v2seHL0pwbg.wav\n",
      "loading normalize_5s_intro_BrrWNfjgHGs.wav\n",
      "loading normalize_5s_intro_j1c70vRHdhQ.wav\n",
      "loading normalize_5s_intro_3DCHLwOqtJs.wav\n",
      "loading normalize_5s_intro_g20t_K9dlhU.wav\n",
      "loading normalize_5s_intro_EH1OEWJ9C5w.wav\n",
      "loading normalize_5s_intro_SCBxmcwmX7U.wav\n",
      "loading normalize_5s_intro_tXvpe2GbUec.wav\n",
      "loading normalize_5s_intro_7ZgPGMfUVek.wav\n",
      "loading normalize_5s_intro_aIJuCcGFJkc.wav\n",
      "loading normalize_5s_intro_RLMl1umHgp0.wav\n",
      "loading normalize_5s_intro_KT-m6qTJyN0.wav\n",
      "loading normalize_5s_intro_WJs-_T8I74Y.wav\n",
      "loading normalize_5s_intro_aIyqRdrHodE.wav\n",
      "loading normalize_5s_intro_XJT-fM4nBJU.wav\n",
      "loading normalize_5s_intro_7QQzDQceGgU.wav\n",
      "loading normalize_5s_intro_fE2h3lGlOsk.wav\n",
      "loading normalize_5s_intro_Oq1n8fUxQZc.wav\n",
      "loading normalize_5s_intro_pssWSj42t8M.wav\n",
      "loading normalize_5s_intro_GsPq9mzFNGY.wav\n",
      "loading normalize_5s_intro_Jg9NbDizoPM.wav\n",
      "loading normalize_5s_intro_Ib7m3Qh-4O4.wav\n",
      "loading normalize_5s_intro_hn3wJ1_1Zsg.wav\n",
      "loading normalize_5s_intro_hjZqVw3qI9E.wav\n",
      "loading normalize_5s_intro_cUKD9tEeBp0.wav\n",
      "loading normalize_5s_intro_q_4no3KCrY4.wav\n",
      "loading normalize_5s_intro_VlWs8ey2nyg.wav\n",
      "loading normalize_5s_intro_Srp0opA8V8o.wav\n",
      "loading normalize_5s_intro_PYM9NUU9Roc.wav\n",
      "loading normalize_5s_intro_v0UvOsCi8mc.wav\n",
      "loading normalize_5s_intro_zaCbuB3w0kg.wav\n",
      "loading normalize_5s_intro_PCp2iXA1uLE.wav\n",
      "loading normalize_5s_intro_S2RnxiNJg0M.wav\n",
      "loading normalize_5s_intro_Jtv4satRsP0.wav\n",
      "loading normalize_5s_intro_ytq5pGcM77w.wav\n",
      "loading normalize_5s_intro_9nWpMZFrbvI.wav\n",
      "loading normalize_5s_intro_1kN-34GFMYM.wav\n",
      "loading normalize_5s_intro_Yyvo9O8fN-A.wav\n",
      "loading normalize_5s_intro_ulj-L3K_Gzs.wav\n",
      "loading normalize_5s_intro_V-ar6MLjy5o.wav\n",
      "loading normalize_5s_intro_dtOv6WvJ44w.wav\n",
      "loading normalize_5s_intro_XkC8Uzl9pCY.wav\n",
      "loading normalize_5s_intro_jII5qoCrzYE.wav\n",
      "loading normalize_5s_intro_7pcZIsJNlAs.wav\n",
      "loading normalize_5s_intro_0QN9KLFWn7I.wav\n",
      "loading normalize_5s_intro_d6BzCEkGd3I.wav\n",
      "loading normalize_5s_intro_lYxcW8jtFw0.wav\n",
      "loading normalize_5s_intro_R1T_SrdQGH8.wav\n",
      "loading normalize_5s_intro_YOKq1VmEbtc.wav\n",
      "loading normalize_5s_intro_19Q9l85Feqw.wav\n",
      "loading normalize_5s_intro_CXm7hPs_als.wav\n",
      "loading normalize_5s_intro_nFOLhtsyvMA.wav\n",
      "loading normalize_5s_intro_-8cFfkyk7vA.wav\n",
      "loading normalize_5s_intro_ZIiQ1jMqhVM.wav\n",
      "loading normalize_5s_intro_hejXc_FSYb8.wav\n",
      "loading normalize_5s_intro_eXvBjCO19QY.wav\n",
      "loading normalize_5s_intro_haCay85cpvo.wav\n",
      "loading normalize_5s_intro_RpJz01guPMY.wav\n",
      "loading normalize_5s_intro_sPlXrbVLdO8.wav\n",
      "loading normalize_5s_intro_Mme9REVuidw.wav\n",
      "loading normalize_5s_intro_UGTYqTKUl8w.wav\n",
      "loading normalize_5s_intro_9DP0yMwvyWE.wav\n",
      "loading normalize_5s_intro_WrDJMxSKlCA.wav\n",
      "loading normalize_5s_intro_2F8Kr91wQ0U.wav\n",
      "loading normalize_5s_intro_gyegm85BPPA.wav\n",
      "loading normalize_5s_intro_Xhh3_-JRnDc.wav\n",
      "loading normalize_5s_intro_WRSeV_27z6k.wav\n",
      "loading normalize_5s_intro_HwcCBnfhsR4.wav\n",
      "loading normalize_5s_intro_bd5m12UEHWI.wav\n",
      "loading normalize_5s_intro_1juIFmPyG-Y.wav\n",
      "loading normalize_5s_intro_DGsoqhIUgDQ.wav\n",
      "loading normalize_5s_intro_2UL-1MOlSPw.wav\n",
      "loading normalize_5s_intro_2AWE9tqnDPw.wav\n",
      "loading normalize_5s_intro_68b_HImZAig.wav\n",
      "loading normalize_5s_intro_GIulOhzXufc.wav\n",
      "loading normalize_5s_intro_Stet_4bnclk.wav\n",
      "loading normalize_5s_intro_RHGfkuJv0j0.wav\n",
      "loading normalize_5s_intro_0uLI6BnVh6w.wav\n",
      "loading normalize_5s_intro_uo6VU4euIbY.wav\n",
      "loading normalize_5s_intro_6pARjpdqxYQ.wav\n",
      "loading normalize_5s_intro_hjIhCG_nIPA.wav\n",
      "loading normalize_5s_intro_hV-FwW1LgxU.wav\n",
      "loading normalize_5s_intro_mWfWyhzC22U.wav\n",
      "loading normalize_5s_intro_IISA6t-9zzc.wav\n",
      "loading normalize_5s_intro_gDevCxVY_wA.wav\n",
      "loading normalize_5s_intro_IrtcCSE2bVY.wav\n",
      "loading normalize_5s_intro_feVUoKhP1mE.wav\n",
      "loading normalize_5s_intro_Tfypj4UwvvA.wav\n",
      "loading normalize_5s_intro_TeH7sCVCMJk.wav\n"
     ]
    }
   ],
   "source": [
    "data_folder_path = \"../data\"\n",
    "track_df, audio_df = read_files(f\"{data_folder_path}/train.csv\", f\"{data_folder_path}/audios/clips\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(track_df, audio_df):\n",
    "    x = np.array([[[value]] for value in audio_df[\"y\"].values])\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape = (220, 1, 1, 110250)\n",
      "y shape = (220, 1)\n"
     ]
    }
   ],
   "source": [
    "# print(audio_df)\n",
    "# for index, (track, y, sr) in audio_df.iterrows():\n",
    "#     print(y)\n",
    "\n",
    "x = preprocess_data(track_df, audio_df)\n",
    "y = np.array([track_df['score'].values]).T\n",
    "\n",
    "# print(x)\n",
    "print(\"x shape =\", x.shape)\n",
    "print(\"y shape =\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.tensor(x, dtype=torch.float32) \n",
    "        self.y = torch.tensor(y, dtype=torch.float32) \n",
    "        self.len = x.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(x=x, y=y)\n",
    "\n",
    "train_test_ratio = 0.8\n",
    "train_size = int(len(dataset) * train_test_ratio)\n",
    "test_size = len(dataset) - train_size\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [train_size, test_size])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, 4), 1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, (1, 4), 1)\n",
    "        self.pool = nn.MaxPool2d((1, 2), 2)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(1763904, 128)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output =self.sigmoid(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader,criterion, optimizer, epoch, log_interval=10):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(f\"output = {output} target = {target} loss = {loss}\")\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device,criterion, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            test_loss += loss  # sum up batch loss\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}\\n'.format(test_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(1, 4), stride=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(1, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=(1, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (fc1): Linear(in_features=1763904, out_features=128, bias=True)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "learning_rate = 0.001\n",
    "gamma = 0.1\n",
    "epochs = 10\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set)\n",
    "test_loader = torch.utils.data.DataLoader(test_set)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Model().to(device)\n",
    "print(model)\n",
    "# criterion = torch.nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adadelta(model.parameters(), lr=learning_rate)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/176 (0%)]\tLoss: 0.006804\n",
      "Train Epoch: 1 [100/176 (57%)]\tLoss: 0.089613\n",
      "\n",
      "Test set: Average loss: 0.0324\n",
      "\n",
      "Train Epoch: 2 [0/176 (0%)]\tLoss: 0.000581\n",
      "Train Epoch: 2 [100/176 (57%)]\tLoss: 0.029903\n",
      "\n",
      "Test set: Average loss: 0.0301\n",
      "\n",
      "Train Epoch: 3 [0/176 (0%)]\tLoss: 0.000015\n",
      "Train Epoch: 3 [100/176 (57%)]\tLoss: 0.061463\n",
      "\n",
      "Test set: Average loss: 0.0300\n",
      "\n",
      "Train Epoch: 4 [0/176 (0%)]\tLoss: 0.003752\n",
      "Train Epoch: 4 [100/176 (57%)]\tLoss: 0.031730\n",
      "\n",
      "Test set: Average loss: 0.0300\n",
      "\n",
      "Train Epoch: 5 [0/176 (0%)]\tLoss: 0.002760\n",
      "Train Epoch: 5 [100/176 (57%)]\tLoss: 0.022081\n",
      "\n",
      "Test set: Average loss: 0.0300\n",
      "\n",
      "Train Epoch: 6 [0/176 (0%)]\tLoss: 0.000021\n",
      "Train Epoch: 6 [100/176 (57%)]\tLoss: 0.007568\n",
      "\n",
      "Test set: Average loss: 0.0300\n",
      "\n",
      "Train Epoch: 7 [0/176 (0%)]\tLoss: 0.001081\n",
      "Train Epoch: 7 [100/176 (57%)]\tLoss: 0.047821\n",
      "\n",
      "Test set: Average loss: 0.0300\n",
      "\n",
      "Train Epoch: 8 [0/176 (0%)]\tLoss: 0.001662\n",
      "Train Epoch: 8 [100/176 (57%)]\tLoss: 0.053716\n",
      "\n",
      "Test set: Average loss: 0.0300\n",
      "\n",
      "Train Epoch: 9 [0/176 (0%)]\tLoss: 0.000910\n",
      "Train Epoch: 9 [100/176 (57%)]\tLoss: 0.062442\n",
      "\n",
      "Test set: Average loss: 0.0300\n",
      "\n",
      "Train Epoch: 10 [0/176 (0%)]\tLoss: 0.008652\n",
      "Train Epoch: 10 [100/176 (57%)]\tLoss: 0.070197\n",
      "\n",
      "Test set: Average loss: 0.0300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, criterion, optimizer, epoch, log_interval=100)\n",
    "    test(model, device, criterion, test_loader)\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder_path = \"../model\"\n",
    "save_model_name = \"model1.pt\"\n",
    "\n",
    "torch.save(model, f\"{model_folder_path}/{save_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading normalize_5s_intro_0EVVKs6DQLo.wav\n",
      "loading normalize_5s_intro_d7to9URtLZ4.wav\n",
      "loading normalize_5s_intro_TzhhbYS9EO4.wav\n",
      "loading normalize_5s_intro_nn5nypm7GG8.wav\n",
      "loading normalize_5s_intro_hed6HkYNA7g.wav\n",
      "loading normalize_5s_intro_rWznOAwxM1g.wav\n",
      "loading normalize_5s_intro_zyQkFh-E4Ak.wav\n",
      "loading normalize_5s_intro_agKkcRXN2iE.wav\n",
      "loading normalize_5s_intro_SZaZU_qi6Xc.wav\n",
      "loading normalize_5s_intro_ZpDQJnI4OhU.wav\n",
      "loading normalize_5s_intro_D4nWzd63jV4.wav\n",
      "loading normalize_5s_intro_9odM1BRqop4.wav\n",
      "loading normalize_5s_intro_F64yFFnZfkI.wav\n",
      "loading normalize_5s_intro_Js2JQH_kt0I.wav\n",
      "loading normalize_5s_intro_Skt_NKI4d6U.wav\n"
     ]
    }
   ],
   "source": [
    "load_model_name = \"success_model1.pt\"\n",
    "\n",
    "model = torch.load(f\"{model_folder_path}/{load_model_name}\")\n",
    "model.eval()\n",
    "\n",
    "test_track_df, test_audio_df = read_files(f\"{data_folder_path}/test.csv\", f\"{data_folder_path}/audios/clips\")\n",
    "test_x = preprocess_data(test_track_df, test_audio_df)\n",
    "\n",
    "output_dict = {\n",
    "    \"track\": [],\n",
    "    \"score\": []\n",
    "}\n",
    "\n",
    "for track, features in zip(test_track_df['track'], test_x):\n",
    "    features = np.array([features])\n",
    "    features = torch.tensor(features, dtype=torch.float32).to(device)\n",
    "    score = model(features)\n",
    "    output_dict[\"track\"].append(track)\n",
    "    output_dict[\"score\"].append(score[0][0].cpu().detach().numpy())\n",
    "\n",
    "output_df = pd.DataFrame(output_dict)\n",
    "output_df.to_csv(f\"{data_folder_path}/submission.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86eeccd87f0af4babcb8dbd19537ae118249bd36969b4c7d14d82db374bb1475"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('hw1-82sFHoS4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
